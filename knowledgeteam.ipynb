{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11935685,"sourceType":"datasetVersion","datasetId":7503984}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nfrom datasets import Dataset\n\ndef load_json(file_path):\n    with open(file_path, 'r', encoding='utf-8') as f:\n        data = json.load(f)  # 直接解析整个JSON数组\n    return data\n\ndef get_datasets(train_path, dev_path, test_path):\n    train_data = load_json(train_path)\n    dev_data = load_json(dev_path)\n    test_data = load_json(test_path)\n\n    train_dataset = Dataset.from_list(train_data)\n    dev_dataset = Dataset.from_list(dev_data)\n    test_dataset = Dataset.from_list(test_data)\n\n    return train_dataset, dev_dataset, test_dataset\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T04:15:41.837478Z","iopub.execute_input":"2025-05-25T04:15:41.837661Z","iopub.status.idle":"2025-05-25T04:15:45.362862Z","shell.execute_reply.started":"2025-05-25T04:15:41.837644Z","shell.execute_reply":"2025-05-25T04:15:45.362080Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\n\ndef get_model_and_tokenizer(model_name='hfl/chinese-macbert-base'):\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n    return tokenizer, model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T04:15:45.364120Z","iopub.execute_input":"2025-05-25T04:15:45.364788Z","iopub.status.idle":"2025-05-25T04:15:56.830098Z","shell.execute_reply.started":"2025-05-25T04:15:45.364759Z","shell.execute_reply":"2025-05-25T04:15:56.829540Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import os\nimport torch\nfrom transformers import Trainer, TrainingArguments\nfrom sklearn.metrics import f1_score\nimport numpy as np\n# from data_loader import get_datasets\n# from model import get_model_and_tokenizer\n\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = np.argmax(pred.predictions, axis=1)\n    macro_f1 = f1_score(labels, preds, average='macro')\n    return {'macro_f1': macro_f1}\n\ndef main():\n    # 自动检测并使用GPU\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"当前使用的设备: {device}\")\n\n    logs_dir = os.path.abspath('./logs')\n    results_dir = os.path.abspath('./results')\n    model_dir = os.path.abspath('./best_model')\n\n    os.makedirs(logs_dir, exist_ok=True)\n    os.makedirs(results_dir, exist_ok=True)\n    os.makedirs(model_dir, exist_ok=True)\n\n    train_dataset, dev_dataset, _ = get_datasets(\n        '/kaggle/input/knowledge-data/data/train.json',\n        '/kaggle/input/knowledge-data/data/dev.json',\n        '/kaggle/input/knowledge-data/data/test.json'\n    )\n\n    tokenizer, model = get_model_and_tokenizer()\n    model.to(device)  # 模型移动到GPU\n\n    def preprocess_function(examples):\n        return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=512)\n\n    tokenized_train = train_dataset.map(preprocess_function, batched=True)\n    tokenized_dev = dev_dataset.map(preprocess_function, batched=True)\n\n    training_args = TrainingArguments(\n        output_dir=results_dir,\n        eval_strategy='epoch',\n        save_strategy='epoch',\n        learning_rate=2e-5,\n        per_device_train_batch_size=16,\n        per_device_eval_batch_size=16,\n        num_train_epochs=3,\n        weight_decay=0.01,\n        logging_dir=logs_dir,\n        logging_steps=10,\n        load_best_model_at_end=True,\n        metric_for_best_model='macro_f1',\n        greater_is_better=True,\n        report_to=\"tensorboard\",  # 让TensorBoard正常工作\n        save_total_limit=2,  # 最多保留2个模型\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=tokenized_train,\n        eval_dataset=tokenized_dev,\n        tokenizer=tokenizer,\n        compute_metrics=compute_metrics\n    )\n\n    print(\"开始训练...\")\n    trainer.train()\n    print(\"训练完成，保存模型中...\")\n\n    trainer.save_model(model_dir)\n    print(f\"模型已保存到: {model_dir}\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T04:15:56.830767Z","iopub.execute_input":"2025-05-25T04:15:56.831276Z","iopub.status.idle":"2025-05-25T06:01:58.782801Z","shell.execute_reply.started":"2025-05-25T04:15:56.831250Z","shell.execute_reply":"2025-05-25T06:01:58.782160Z"}},"outputs":[{"name":"stderr","text":"2025-05-25 04:15:58.962582: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748146559.175681      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748146559.230417      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"当前使用的设备: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/19.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6d5849d1cc5448997c72686b5f21df4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1218b5352a19425b8e16cb9e47d983a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07ecdadfe06c45879f31edb34b32f4e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/269k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4714b1e0abf4a4ba8ca221366213863"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fcd481da6854bd8a6b53c3aa3236062"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f186d8c78d094550bb5f759293cbabbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/412M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bd3b4314a2746c29d384ad97300187f"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/chinese-macbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/32400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"525b813b744d46e7adf5e6d20bb5f865"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2800 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1768ff5c2a84038a3993616ffea3669"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_35/173421961.py:61: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"name":"stdout","text":"开始训练...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6075' max='6075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6075/6075 1:45:11, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Macro F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.000300</td>\n      <td>1.915368</td>\n      <td>0.679208</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.000000</td>\n      <td>1.064008</td>\n      <td>0.847486</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.000000</td>\n      <td>1.530207</td>\n      <td>0.786939</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"训练完成，保存模型中...\n模型已保存到: /kaggle/working/best_model\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import json\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\nfrom tqdm import tqdm\n\ndef main():\n    # 判断是否有可用的GPU\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # 加载数据和模型\n    test_data = load_json('/kaggle/input/knowledge-data/data/test.json')  # 请确保文件路径正确\n    tokenizer = AutoTokenizer.from_pretrained('./best_model')\n    model = AutoModelForSequenceClassification.from_pretrained('./best_model')\n    \n    # 将模型转移到GPU\n    model.to(device)\n    model.eval()\n\n    results = []\n    for item in tqdm(test_data):\n        # 将输入数据转移到GPU\n        inputs = tokenizer(item['text'], return_tensors='pt', truncation=True, padding=True, max_length=512)\n        inputs = {key: value.to(device) for key, value in inputs.items()}\n        \n        with torch.no_grad():\n            # 在GPU上进行推理\n            outputs = model(**inputs)\n            logits = outputs.logits\n            predicted_label = torch.argmax(logits, dim=1).item()\n        \n        results.append({\n            'id': item['id'],\n            'text': item['text'],\n            'label': predicted_label\n        })\n\n    # 将结果保存到文件\n    with open('submission.json', 'w', encoding='utf-8') as f:\n        for result in results:\n            f.write(json.dumps(result, ensure_ascii=False) + '\\n')\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T06:12:48.782062Z","iopub.execute_input":"2025-05-25T06:12:48.782345Z","iopub.status.idle":"2025-05-25T06:16:06.056655Z","shell.execute_reply.started":"2025-05-25T06:12:48.782323Z","shell.execute_reply":"2025-05-25T06:16:06.056045Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 11000/11000 [03:16<00:00, 55.88it/s]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import json\n\n# 加载 submission.json\nsubmission = {}\nwith open('submission.json', 'r', encoding='utf-8') as f:\n    for line in f:\n        item = json.loads(line)\n        submission[item['id']] = item['label']\n\n# 加载 test_with_label.json\nwith open('/kaggle/input/knowledge-data/data/test_with_label.json', 'r', encoding='utf-8') as f:\n    test_data = json.load(f)\n\n# 进行比对\ncorrect = 0\ntotal = 0\n\nfor item in test_data:\n    id_ = item['id']\n    true_label = item['label']\n    pred_label = submission.get(id_, None)\n    \n    if pred_label is not None:\n        if pred_label == true_label:\n            correct += 1\n        total += 1\n\naccuracy = correct / total if total > 0 else 0\nprint(f\"总样本数: {total}\")\nprint(f\"预测正确数: {correct}\")\nprint(f\"准确率: {accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T06:24:47.851732Z","iopub.execute_input":"2025-05-25T06:24:47.852499Z","iopub.status.idle":"2025-05-25T06:24:48.270393Z","shell.execute_reply.started":"2025-05-25T06:24:47.852464Z","shell.execute_reply":"2025-05-25T06:24:48.269771Z"}},"outputs":[{"name":"stdout","text":"总样本数: 11000\n预测正确数: 8949\n准确率: 0.8135\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import os\nimport zipfile\nimport datetime\n\ndef file2zip(packagePath, zipPath):\n    '''\n  :param packagePath: 文件夹路径\n  :param zipPath: 压缩包路径\n  :return:\n  '''\n    zip = zipfile.ZipFile(zipPath, 'w', zipfile.ZIP_DEFLATED)\n    for path, dirNames, fileNames in os.walk(packagePath):\n        fpath = path.replace(packagePath, '')\n        for name in fileNames:\n            fullName = os.path.join(path, name)\n            name = fpath + '\\\\' + name\n            zip.write(fullName, name)\n    zip.close()\n\n\nif __name__ == \"__main__\":\n    # 文件夹路径\n    packagePath = '/kaggle/working/'\n    zipPath = '/kaggle/working/output.zip'\n    if os.path.exists(zipPath):\n        os.remove(zipPath)\n    file2zip(packagePath, zipPath)\n    print(\"打包完成\")\n    print(datetime.datetime.utcnow())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T06:16:36.449770Z","iopub.execute_input":"2025-05-25T06:16:36.450301Z","iopub.status.idle":"2025-05-25T06:18:52.942623Z","shell.execute_reply.started":"2025-05-25T06:16:36.450276Z","shell.execute_reply":"2025-05-25T06:18:52.941982Z"}},"outputs":[{"name":"stdout","text":"打包完成\n2025-05-25 06:18:52.940135\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import os\nos.chdir('/kaggle/working')\nprint(os.getcwd())\nprint(os.listdir(\"/kaggle/working\"))\nfrom IPython.display import FileLink\nFileLink('output.zip')\n\n\n#下面就会有文件的下载链接，直接点击下载即可\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T06:31:14.064257Z","iopub.execute_input":"2025-05-25T06:31:14.064763Z","iopub.status.idle":"2025-05-25T06:31:14.071368Z","shell.execute_reply.started":"2025-05-25T06:31:14.064739Z","shell.execute_reply":"2025-05-25T06:31:14.070751Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n['output.zip', 'logs', 'results', 'submission.json', '.virtual_documents', 'best_model']\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/output.zip","text/html":"<a href='output.zip' target='_blank'>output.zip</a><br>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}